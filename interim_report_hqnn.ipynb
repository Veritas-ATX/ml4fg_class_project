{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263a3272-e8cd-4b51-9aaf-932ce45fb06d",
   "metadata": {},
   "source": [
    "# ML4FG Interim Report HQNN Code\n",
    "### By: Austin Stiefelmaier 11/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f775c36-6b70-41d0-8e66-e17f5b94e34f",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by quantum ML code from:\n",
    "# https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html\n",
    "# And classical ML code from:\n",
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbadb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Pennylane imports\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcb8f46-b67f-4c99-afdf-0a6a980f1dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Fix random num generation for reproducibility \n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "# If GPU available, set to run on it\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94266a11-f651-4e30-9fb5-885f6715ffe7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d566b0e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data download\n",
    "df_x = pd.read_csv('/home/as6734/ml4fg_class_project/TCGA-PANCAN-HiSeq-801x20531/data.csv')\n",
    "df_y = pd.read_csv('/home/as6734/ml4fg_class_project/TCGA-PANCAN-HiSeq-801x20531/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a746ad56-e2cc-44e9-aa3f-a23a466154d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.926711</td>\n",
       "      <td>8.210257</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.593372</td>\n",
       "      <td>7.323865</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.125213</td>\n",
       "      <td>8.127123</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.076566</td>\n",
       "      <td>8.792959</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.996032</td>\n",
       "      <td>8.891425</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
       "0   sample_0     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
       "1   sample_1     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
       "2   sample_2     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
       "3   sample_3     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
       "4   sample_4     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
       "\n",
       "     gene_6    gene_7  gene_8  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "0  7.175175  0.591871     0.0  ...    4.926711    8.210257    9.723516   \n",
       "1  6.816049  0.000000     0.0  ...    4.593372    7.323865    9.740931   \n",
       "2  6.972130  0.452595     0.0  ...    5.125213    8.127123   10.908640   \n",
       "3  7.843375  0.434882     0.0  ...    6.076566    8.792959   10.141520   \n",
       "4  6.566967  0.360982     0.0  ...    5.996032    8.891425   10.373790   \n",
       "\n",
       "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
       "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
       "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
       "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
       "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
       "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
       "\n",
       "   gene_20530  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 20532 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dbea41-439d-4299-b1c5-ad1a2bbf4d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>PRAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_4</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Class\n",
       "0   sample_0  PRAD\n",
       "1   sample_1  LUAD\n",
       "2   sample_2  PRAD\n",
       "3   sample_3  PRAD\n",
       "4   sample_4  BRCA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c85d30-ced3-476c-9121-29c57dbe33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "# Drop first column that only notes sample number (which can be reconstructed from index if need be\n",
    "df_x.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_y.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "# Remove columns with all 0.0 values\n",
    "df_x = df_x.loc[:, (df_x != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4dc4c81-aa50-41a8-a112-e0b8e69d2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "\n",
    "# Normalize values by mean\n",
    "df_x=(df_x-df_x.mean())/df_x.std()\n",
    "# Encode classes\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(df_y.values)\n",
    "y = enc.transform(df_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fceb70b6-fa92-4f05-9dfa-c13a0362017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>gene_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.194678</td>\n",
       "      <td>-0.827513</td>\n",
       "      <td>0.159701</td>\n",
       "      <td>-1.947061</td>\n",
       "      <td>1.220812</td>\n",
       "      <td>-0.207838</td>\n",
       "      <td>0.180797</td>\n",
       "      <td>-0.125297</td>\n",
       "      <td>-0.065592</td>\n",
       "      <td>-0.082063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.299388</td>\n",
       "      <td>-0.921179</td>\n",
       "      <td>-0.877290</td>\n",
       "      <td>0.995625</td>\n",
       "      <td>-1.165344</td>\n",
       "      <td>0.389198</td>\n",
       "      <td>-0.869023</td>\n",
       "      <td>-1.187196</td>\n",
       "      <td>-0.116410</td>\n",
       "      <td>-0.261738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.194678</td>\n",
       "      <td>-2.013759</td>\n",
       "      <td>-1.414158</td>\n",
       "      <td>1.352264</td>\n",
       "      <td>-0.376283</td>\n",
       "      <td>-0.531890</td>\n",
       "      <td>-0.982474</td>\n",
       "      <td>-0.125297</td>\n",
       "      <td>-0.065592</td>\n",
       "      <td>-0.586397</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.745985</td>\n",
       "      <td>-2.390720</td>\n",
       "      <td>-0.831373</td>\n",
       "      <td>0.591280</td>\n",
       "      <td>-2.548006</td>\n",
       "      <td>1.390759</td>\n",
       "      <td>0.623162</td>\n",
       "      <td>-0.342063</td>\n",
       "      <td>-1.655854</td>\n",
       "      <td>-0.261738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.194678</td>\n",
       "      <td>0.417087</td>\n",
       "      <td>1.156013</td>\n",
       "      <td>0.249651</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>-0.391053</td>\n",
       "      <td>-0.092937</td>\n",
       "      <td>-0.125297</td>\n",
       "      <td>-0.065592</td>\n",
       "      <td>-0.586397</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033442</td>\n",
       "      <td>-1.059008</td>\n",
       "      <td>2.247399</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.317682</td>\n",
       "      <td>-4.023107</td>\n",
       "      <td>-0.631986</td>\n",
       "      <td>0.886307</td>\n",
       "      <td>-1.854106</td>\n",
       "      <td>-0.261738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.194678</td>\n",
       "      <td>0.543549</td>\n",
       "      <td>1.325354</td>\n",
       "      <td>-0.098991</td>\n",
       "      <td>0.755269</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>-0.127752</td>\n",
       "      <td>-0.125297</td>\n",
       "      <td>-0.065592</td>\n",
       "      <td>-0.586397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241148</td>\n",
       "      <td>0.044877</td>\n",
       "      <td>0.224815</td>\n",
       "      <td>1.718651</td>\n",
       "      <td>-0.263682</td>\n",
       "      <td>-0.521421</td>\n",
       "      <td>-0.793113</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>-1.078268</td>\n",
       "      <td>-0.261738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.194678</td>\n",
       "      <td>-0.295770</td>\n",
       "      <td>-0.256947</td>\n",
       "      <td>-0.286234</td>\n",
       "      <td>-0.148750</td>\n",
       "      <td>-0.756645</td>\n",
       "      <td>-0.272995</td>\n",
       "      <td>-0.125297</td>\n",
       "      <td>-0.065592</td>\n",
       "      <td>-0.586397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133251</td>\n",
       "      <td>0.208122</td>\n",
       "      <td>0.837216</td>\n",
       "      <td>0.979312</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.268824</td>\n",
       "      <td>-1.614832</td>\n",
       "      <td>-0.229734</td>\n",
       "      <td>-0.201463</td>\n",
       "      <td>-0.261738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_0    gene_1    gene_2    gene_3    gene_4    gene_6    gene_7  \\\n",
       "0 -0.194678 -0.827513  0.159701 -1.947061  1.220812 -0.207838  0.180797   \n",
       "1 -0.194678 -2.013759 -1.414158  1.352264 -0.376283 -0.531890 -0.982474   \n",
       "2 -0.194678  0.417087  1.156013  0.249651  0.112761 -0.391053 -0.092937   \n",
       "3 -0.194678  0.543549  1.325354 -0.098991  0.755269  0.395101 -0.127752   \n",
       "4 -0.194678 -0.295770 -0.256947 -0.286234 -0.148750 -0.756645 -0.272995   \n",
       "\n",
       "     gene_8    gene_9   gene_10  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "0 -0.125297 -0.065592 -0.082063  ...   -1.299388   -0.921179   -0.877290   \n",
       "1 -0.125297 -0.065592 -0.586397  ...   -1.745985   -2.390720   -0.831373   \n",
       "2 -0.125297 -0.065592 -0.586397  ...   -1.033442   -1.059008    2.247399   \n",
       "3 -0.125297 -0.065592 -0.586397  ...    0.241148    0.044877    0.224815   \n",
       "4 -0.125297 -0.065592 -0.586397  ...    0.133251    0.208122    0.837216   \n",
       "\n",
       "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
       "0    0.995625   -1.165344    0.389198   -0.869023   -1.187196   -0.116410   \n",
       "1    0.591280   -2.548006    1.390759    0.623162   -0.342063   -1.655854   \n",
       "2    0.232456    0.317682   -4.023107   -0.631986    0.886307   -1.854106   \n",
       "3    1.718651   -0.263682   -0.521421   -0.793113    0.166070   -1.078268   \n",
       "4    0.979312    0.196522    0.268824   -1.614832   -0.229734   -0.201463   \n",
       "\n",
       "   gene_20530  \n",
       "0   -0.261738  \n",
       "1   -0.261738  \n",
       "2   -0.261738  \n",
       "3   -0.261738  \n",
       "4   -0.261738  \n",
       "\n",
       "[5 rows x 20264 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe1cdcb-124d-4741-8854-c379f7b4c654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c92ec11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data, final percentages are approximately 64% train, 16% validation, 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x.values, y, test_size=0.2, train_size=0.8, random_state=7, stratify=y)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, train_size=0.8, random_state=7, stratify=y_train)\n",
    "dataset_sizes = {'train': len(x_train), 'validation': len(x_valid), 'test': len(x_test)}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22283318-279b-4514-8a88-dfc8ef9f47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoaders\n",
    "x_train_to_tensor = torch.from_numpy(x_train).to(torch.float32)\n",
    "y_train_to_tensor = torch.from_numpy(y_train).to(torch.int) \n",
    "x_valid_to_tensor = torch.from_numpy(x_valid).to(torch.float32)\n",
    "y_valid_to_tensor = torch.from_numpy(y_valid).to(torch.int)\n",
    "x_test_to_tensor = torch.from_numpy(x_test).to(torch.float32)\n",
    "y_test_to_tensor = torch.from_numpy(y_test).to(torch.int)\n",
    "\n",
    "# Second step: Creating TensorDataset for Dataloader\n",
    "train_set = TensorDataset(x_train_to_tensor, y_train_to_tensor)\n",
    "valid_set = TensorDataset(x_valid_to_tensor, y_valid_to_tensor)\n",
    "test_set = TensorDataset(x_test_to_tensor, y_test_to_tensor)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True),\n",
    "    'validation': torch.utils.data.DataLoader(valid_set, batch_size=8),\n",
    "    'test': torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40e428",
   "metadata": {},
   "source": [
    "## Quantum Circuit Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b4fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model architecture/training params\n",
    "qubit_count = 5\n",
    "step = 0.0004  # Initial learning rate\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "circ_repeats = 6  # How many times to repeat RY and CNOT gates\n",
    "gamma_lr_scheduler = 0.1  # Learning rate decay param\n",
    "q_delta = 0.01  # Param for quantum circuit weight initialization\n",
    "\n",
    "# Run quantum circuit on Pennylane default simulator\n",
    "dev = qml.device('default.qubit', wires=qubit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to construct quantum circuit\n",
    "def ry_gates(w):\n",
    "    # Apply rotation gate RY w/ given weights\n",
    "    for i, weight in enumerate(w):\n",
    "        qml.RY(weight, wires=i)\n",
    "\n",
    "# Adds alternating CNOT layer to entangle qubits\n",
    "def entangling_layer(nqubits):\n",
    "    for i in range(0, nqubits - 1, 2):  # Evens\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Odds\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f695c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct quantum circuit to plug into PyTorch\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_circuit(inputs, q_weights_flat):\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(circ_repeats, qubit_count)\n",
    "    # Initialize w/ H gates so orthogonal to computational basis\n",
    "    # This helps start w/out bias towards 0 or 1 states\n",
    "    for i in range(qubit_count):\n",
    "        qml.Hadamard(wires=i)\n",
    "    # Take given inputs and apply to quantum circuit as first weights\n",
    "    ry_gates(inputs)\n",
    "    # Repeat CNOT and RY gates to add more weights to train and\n",
    "    # CNOT \"convolutions\" (really entangles)\n",
    "    for k in range(circ_repeats):\n",
    "        entangling_layer(qubit_count)\n",
    "        ry_gates(q_weights[k])\n",
    "    # Use Pennylane sim to get expected value after applying Z gate\n",
    "    # which returns to standard computational basis, this is layer output\n",
    "    expected_vals = [qml.expval(qml.PauliZ(entry)) for entry in range(qubit_count)]\n",
    "    return tuple(expected_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "293270e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──H──RY(-0.15)─╭●──RY(-0.01)────────────╭●──RY(0.00)────────────╭●──RY(-0.01)────────────╭●\n",
      "1: ──H──RY(0.69)──╰X─╭●──────────RY(0.00)──╰X─╭●─────────RY(-0.01)─╰X─╭●──────────RY(-0.00)─╰X\n",
      "2: ──H──RY(0.21)──╭●─╰X──────────RY(0.01)──╭●─╰X─────────RY(-0.01)─╭●─╰X──────────RY(0.01)──╭●\n",
      "3: ──H──RY(-0.84)─╰X─╭●──────────RY(-0.01)─╰X─╭●─────────RY(0.01)──╰X─╭●──────────RY(0.01)──╰X\n",
      "4: ──H──RY(-0.98)────╰X──────────RY(-0.00)────╰X─────────RY(-0.01)────╰X──────────RY(-0.01)───\n",
      "\n",
      "───RY(0.01)────────────╭●──RY(0.01)────────────╭●──RY(0.01)────────────┤  <Z>\n",
      "──╭●─────────RY(-0.00)─╰X─╭●─────────RY(-0.01)─╰X─╭●─────────RY(0.02)──┤  <Z>\n",
      "──╰X─────────RY(-0.00)─╭●─╰X─────────RY(0.01)──╭●─╰X─────────RY(-0.01)─┤  <Z>\n",
      "──╭●─────────RY(0.00)──╰X─╭●─────────RY(0.01)──╰X─╭●─────────RY(-0.00)─┤  <Z>\n",
      "──╰X─────────RY(0.02)─────╰X─────────RY(-0.01)────╰X─────────RY(-0.00)─┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "# Example visualization codes with nonsense weights\n",
    "# Helps to see what the quantum circuit looks like\n",
    "q_params_print = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "input_test = torch.randn(1,512)\n",
    "pre_net_test = nn.Linear(512, qubit_count)\n",
    "pre_out_test = pre_net_test(input_test)\n",
    "q_in_test = torch.tanh(pre_out_test) * np.pi / 2.0\n",
    "for elem in q_in_test:\n",
    "    print(qml.draw(quantum_circuit)(elem, q_params_print))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916720a3-5e54-4bee-b428-7be9e3252bdc",
   "metadata": {},
   "source": [
    "## HQNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c56560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HQNN Model Class\n",
    "class HybridQuantumNet(nn.Module):\n",
    "    # Initialize layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layers before quantum circuit\n",
    "        self.pre_quant = nn.Linear(512, qubit_count)\n",
    "        # Quantum Circuit params\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "        # Layer(s) after quantum circuit\n",
    "        self.post_quant = nn.Linear(qubit_count, 2)\n",
    "\n",
    "    # Forward pass procedure\n",
    "    def forward(self, input_features):\n",
    "        # Map 512 output to qubit_count output\n",
    "        pre_out = self.pre_quant(input_features)\n",
    "        # Convert to radians for use as RY rotation gate params\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "        # Apply quantum circuit to each batch image, set to run on GPU\n",
    "        q_out = torch.Tensor(0, qubit_count)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_circuit(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "        # Map quantum circuit output using linear layer to classes\n",
    "        return self.post_quant(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model_hybrid = HybridQuantumNet()\n",
    "# Make sure set to use GPU\n",
    "model_hybrid = model_hybrid.to(device)\n",
    "# Show model architecture summary\n",
    "model_hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ef09c-cd06-41b8-bd44-35bded59fab8",
   "metadata": {},
   "source": [
    "## Train HQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24238e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss, optimizer, and learning rate decay manager\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model(s)\n",
    "def train(model, loss_func, optimizer, scheduler, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 100000.0\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 100000.0\n",
    "    print('Training started:')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                # Set model to train mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to eval mode\n",
    "                model.eval()\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            iter = 0\n",
    "            for X, Y in dataloaders[phase]:\n",
    "                batch_len = len(X)\n",
    "                X = X.to(device)\n",
    "                X = X.to(device)\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "                # If in train mode, get loss, step optimizer\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(X)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = loss_func(outputs, Y)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Print iteration results\n",
    "                current_loss += loss.item() * batch_len\n",
    "                batch_corrects = torch.sum(preds == X.data).item()\n",
    "                current_corrects += batch_corrects\n",
    "                print('Phase: {} Epoch: {}/{} Iter: {}/{}'.format(phase, epoch+1, num_epochs, iter+1, n_batches+1),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True)\n",
    "                iter += 1\n",
    "\n",
    "            # Get epoch stats and print\n",
    "            epoch_loss = current_loss / dataset_sizes[phase]\n",
    "            epoch_acc = current_corrects / dataset_sizes[phase]\n",
    "            print('Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        '.format(\n",
    "                    'train' if phase == 'train' else 'validation  ',\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "            # Update best var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = train(model_hybrid, loss_func, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights locally in case of GCP crash\n",
    "torch.save(model_hybrid.state_dict(), './weights/hybrid_10epochs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd073d9f-88a8-43c1-a147-1a6ca3baef3c",
   "metadata": {},
   "source": [
    "## Test HQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef720e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved weights, put in model, and than set to eval mode\n",
    "best_weights = torch.load('./weights/hybrid_10epochs.pt')\n",
    "model_hybrid.load_state_dict(best_weights)\n",
    "model_hybrid.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04835ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests model (if epsilon=0, standard test set images)\n",
    "# Otherwise perturbs using FGSM attack\n",
    "# Also stores example images where the perturbation caused a mislabel\n",
    "def test(model, device, test_loader, epsilon):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # Send the data and label to GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # Don't care to attack if already wrong\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "        # Get loss backprop for gradient values\n",
    "        loss = F.nll_loss(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # Collect gradients\n",
    "        data_grad = data.grad.data\n",
    "        # Call FGSM function\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if epsilon == 0 and len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "    # Get accuracy metric\n",
    "    final_acc = correct / float(dataset_sizes['test'])\n",
    "    print('Epsilon: {}\\tTest Accuracy = {} / {} = {}'.format(epsilon, correct, len(test_loader), final_acc))\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e278d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
