{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263a3272-e8cd-4b51-9aaf-932ce45fb06d",
   "metadata": {},
   "source": [
    "# ML4FG Interim Report HQNN Code\n",
    "### By: Austin Stiefelmaier 11/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f775c36-6b70-41d0-8e66-e17f5b94e34f",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bce9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by quantum ML code from:\n",
    "# https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html\n",
    "# And classical ML code from:\n",
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbadb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Pennylane imports\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb8f46-b67f-4c99-afdf-0a6a980f1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random num generation for reproducibility \n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94266a11-f651-4e30-9fb5-885f6715ffe7",
   "metadata": {},
   "source": [
    "## Data Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566b0e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data download\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92ec11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from folder\n",
    "data_folder = '/home/as6734/ml4fg_class_project/data/MYFOLDERNAME'\n",
    "# Split data\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(all_data, [16000, 2000, 2000], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71bcef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "dataset_sizes = {'train': 16000, 'validation': 2000, 'test': 2000}\n",
    "class_names = all_data.classes\n",
    "batch_size = 8\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "    'validation': torch.utils.data.DataLoader(valid_set, batch_size=batch_size),\n",
    "    'test': torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40e428",
   "metadata": {},
   "source": [
    "## HQNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b4fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model architecture/training params\n",
    "qubit_count = 4\n",
    "step = 0.0004  # Initial learning rate\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "circ_repeats = 6  # How many times to repeat RY and CNOT gates\n",
    "gamma_lr_scheduler = 0.1  # Learning rate decay param\n",
    "q_delta = 0.01  # Param for quantum circuit weight initialization\n",
    "\n",
    "# Run quantum circuit on Pennylane default simulator\n",
    "dev = qml.device('default.qubit', wires=qubit_count)\n",
    "\n",
    "# If GPU available, set to run on it\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to construct quantum circuit\n",
    "def ry_gates(w):\n",
    "    # Apply rotation gate RY w/ given weights\n",
    "    for i, weight in enumerate(w):\n",
    "        qml.RY(weight, wires=i)\n",
    "\n",
    "# Adds alternating CNOT layer to entangle qubits\n",
    "def entangling_layer(nqubits):\n",
    "    for i in range(0, nqubits - 1, 2):  # Evens\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Odds\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f695c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct quantum circuit to plug into PyTorch\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_circuit(inputs, q_weights_flat):\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(circ_repeats, qubit_count)\n",
    "    # Initialize w/ H gates so orthogonal to computational basis\n",
    "    # This helps start w/out bias towards 0 or 1 states\n",
    "    for i in range(qubit_count):\n",
    "        qml.Hadamard(wires=i)\n",
    "    # Take given inputs and apply to quantum circuit as first weights\n",
    "    ry_gates(inputs)\n",
    "    # Repeat CNOT and RY gates to add more weights to train and\n",
    "    # CNOT \"convolutions\" (really entangles)\n",
    "    for k in range(circ_repeats):\n",
    "        entangling_layer(qubit_count)\n",
    "        ry_gates(q_weights[k])\n",
    "    # Use Pennylane sim to get expected value after applying Z gate\n",
    "    # which returns to standard computational basis, this is layer output\n",
    "    expected_vals = [qml.expval(qml.PauliZ(entry)) for entry in range(qubit_count)]\n",
    "    return tuple(expected_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c56560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend PyTorch Module class to describe the replacement layer\n",
    "# for ResNet-18's final fc layer\n",
    "class HybridQuantumNet(nn.Module):\n",
    "    # Initialize layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pre_quant = nn.Linear(512, qubit_count)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "        self.post_quant = nn.Linear(qubit_count, 2)\n",
    "\n",
    "    # Forward pass procedure\n",
    "    def forward(self, input_features):\n",
    "        # Map 512 output to qubit_count output\n",
    "        pre_out = self.pre_quant(input_features)\n",
    "        # Convert to radians for use as RY rotation gate params\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "        # Apply quantum circuit to each batch image, set to run on GPU\n",
    "        q_out = torch.Tensor(0, qubit_count)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_circuit(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "        # Map quantum circuit output using linear layer to classes\n",
    "        return self.post_quant(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "036f4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze weights for pre-trained model\n",
    "for param in model_hybrid.parameters():\n",
    "    param.requires_grad = False\n",
    "# Replace final fully connected layer of ResNet-18 with quantum net\n",
    "model_hybrid.fc = HybridQuantumNet()\n",
    "# Make sure set to use GPU\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24238e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss, optimizer, and learning rate decay manager\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model(s)\n",
    "def train(model, loss_func, optimizer, scheduler, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 100000.0\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 100000.0\n",
    "    print('Training started:')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                # Set model to train mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to eval mode\n",
    "                model.eval()\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            iter = 0\n",
    "            for X, Y in dataloaders[phase]:\n",
    "                batch_len = len(X)\n",
    "                X = X.to(device)\n",
    "                X = X.to(device)\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "                # If in train mode, get loss, step optimizer\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(X)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = loss_func(outputs, Y)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Print iteration results\n",
    "                current_loss += loss.item() * batch_len\n",
    "                batch_corrects = torch.sum(preds == X.data).item()\n",
    "                current_corrects += batch_corrects\n",
    "                print('Phase: {} Epoch: {}/{} Iter: {}/{}'.format(phase, epoch+1, num_epochs, iter+1, n_batches+1),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True)\n",
    "                iter += 1\n",
    "\n",
    "            # Get epoch stats and print\n",
    "            epoch_loss = current_loss / dataset_sizes[phase]\n",
    "            epoch_acc = current_corrects / dataset_sizes[phase]\n",
    "            print('Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        '.format(\n",
    "                    'train' if phase == 'train' else 'validation  ',\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "            # Update best var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ade40fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train Epoch: 1/10 Loss: 0.2376 Acc: 0.9451        \n",
      "Phase: validation Epoch: 1/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▏                                                                | 1/10 [16:00<2:24:00, 960.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 1/10 Loss: 0.1454 Acc: 0.9615        \n",
      "Phase: train Epoch: 2/10 Loss: 0.1238 Acc: 0.9679        \n",
      "Phase: validation Epoch: 2/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▍                                                         | 2/10 [31:07<2:03:51, 929.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 2/10 Loss: 0.1046 Acc: 0.9690        \n",
      "Phase: train Epoch: 3/10 Loss: 0.1018 Acc: 0.9675        \n",
      "Phase: validation Epoch: 3/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▌                                                  | 3/10 [46:04<1:46:42, 914.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 3/10 Loss: 0.0852 Acc: 0.9760        \n",
      "Phase: train Epoch: 4/10 Loss: 0.0790 Acc: 0.9745        \n",
      "Phase: validation Epoch: 4/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████                                          | 4/10 [1:00:59<1:30:39, 906.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 4/10 Loss: 0.0788 Acc: 0.9750        \n",
      "Phase: train Epoch: 5/10 Loss: 0.0788 Acc: 0.9727        \n",
      "Phase: validation Epoch: 5/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████                                   | 5/10 [1:15:54<1:15:12, 902.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 5/10 Loss: 0.0737 Acc: 0.9755        \n",
      "Phase: train Epoch: 6/10 Loss: 0.0723 Acc: 0.9735        \n",
      "Phase: validation Epoch: 6/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▏                            | 6/10 [1:30:47<59:57, 899.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 6/10 Loss: 0.0694 Acc: 0.9785        \n",
      "Phase: train Epoch: 7/10 Loss: 0.0644 Acc: 0.9762        \n",
      "Phase: validation Epoch: 7/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████▍                     | 7/10 [1:45:42<44:53, 897.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 7/10 Loss: 0.0791 Acc: 0.9730        \n",
      "Phase: train Epoch: 8/10 Loss: 0.0636 Acc: 0.9772        \n",
      "Phase: validation Epoch: 8/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████▌              | 8/10 [2:00:42<29:57, 898.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 8/10 Loss: 0.0630 Acc: 0.9790        \n",
      "Phase: train Epoch: 9/10 Loss: 0.0659 Acc: 0.9747        \n",
      "Phase: validation Epoch: 9/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████▊       | 9/10 [2:15:40<14:58, 898.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 9/10 Loss: 0.0653 Acc: 0.9795        \n",
      "Phase: train Epoch: 10/10 Loss: 0.0647 Acc: 0.9749        \n",
      "Phase: validation Epoch: 10/10 Iter: 40/41\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 10/10 [2:30:39<00:00, 903.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: validation   Epoch: 10/10 Loss: 0.0591 Acc: 0.9825        \n",
      "Best test loss: 0.0591 | Best test accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_hybrid = train(model_hybrid, loss_func, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights locally in case of GCP crash\n",
    "torch.save(model_hybrid.state_dict(), './weights/hybrid_10epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef720e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): DressedQuantumNet(\n",
       "    (pre_net): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (post_net): Linear(in_features=4, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in saved weights, put in model, and than set to eval mode\n",
    "best_weights = torch.load('./weights/hybrid_10epochs.pt')\n",
    "model_hybrid.load_state_dict(best_weights)\n",
    "model_hybrid.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "293270e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──H──RY(0.12)──╭●──RY(-0.00)───────────╭●──RY(-0.01)────────────╭●──RY(-0.02)────────────╭●\n",
      "1: ──H──RY(-0.07)─╰X─╭●──────────RY(0.00)─╰X─╭●──────────RY(0.00)──╰X─╭●──────────RY(-0.01)─╰X\n",
      "2: ──H──RY(-0.72)─╭●─╰X──────────RY(0.00)─╭●─╰X──────────RY(-0.00)─╭●─╰X──────────RY(0.01)──╭●\n",
      "3: ──H──RY(0.65)──╰X──RY(-0.01)───────────╰X──RY(-0.00)────────────╰X──RY(0.01)─────────────╰X\n",
      "\n",
      "───RY(-0.00)────────────╭●──RY(0.02)────────────╭●──RY(0.00)────────────┤  <Z>\n",
      "──╭●──────────RY(-0.02)─╰X─╭●─────────RY(0.00)──╰X─╭●──────────RY(0.02)─┤  <Z>\n",
      "──╰X──────────RY(-0.01)─╭●─╰X─────────RY(-0.00)─╭●─╰X──────────RY(0.01)─┤  <Z>\n",
      "───RY(0.00)─────────────╰X──RY(0.02)────────────╰X──RY(-0.01)───────────┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "# Example visualization codes with nonsense weights\n",
    "# Helps to see what the quantum circuit looks like\n",
    "q_params_print = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "input_test = torch.randn(1,512)\n",
    "pre_net_test = nn.Linear(512, qubit_count)\n",
    "pre_out_test = pre_net_test(input_test)\n",
    "q_in_test = torch.tanh(pre_out_test) * np.pi / 2.0\n",
    "for elem in q_in_test:\n",
    "    print(qml.draw(quantum_circuit)(elem, q_params_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04835ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests model (if epsilon=0, standard test set images)\n",
    "# Otherwise perturbs using FGSM attack\n",
    "# Also stores example images where the perturbation caused a mislabel\n",
    "def test(model, device, test_loader, epsilon):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # Send the data and label to GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # Don't care to attack if already wrong\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "        # Get loss backprop for gradient values\n",
    "        loss = F.nll_loss(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # Collect gradients\n",
    "        data_grad = data.grad.data\n",
    "        # Call FGSM function\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if epsilon == 0 and len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "    # Get accuracy metric\n",
    "    final_acc = correct / float(dataset_sizes['test'])\n",
    "    print('Epsilon: {}\\tTest Accuracy = {} / {} = {}'.format(epsilon, correct, len(test_loader), final_acc))\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e278d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
