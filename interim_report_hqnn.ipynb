{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263a3272-e8cd-4b51-9aaf-932ce45fb06d",
   "metadata": {},
   "source": [
    "# ML4FG Interim Report HQNN Code\n",
    "### By: Austin Stiefelmaier 11/11/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f775c36-6b70-41d0-8e66-e17f5b94e34f",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by quantum ML code from:\n",
    "# https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html\n",
    "# And classical ML code from:\n",
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbadb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Pennylane imports\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcb8f46-b67f-4c99-afdf-0a6a980f1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random num generation for reproducibility \n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94266a11-f651-4e30-9fb5-885f6715ffe7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566b0e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data download\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ec11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from folder\n",
    "data_folder = '/home/as6734/ml4fg_class_project/data/MYFOLDERNAME'\n",
    "# Split data\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(all_data, [16000, 2000, 2000], generator=torch.Generator().manual_seed(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "dataset_sizes = {'train': 16000, 'validation': 2000, 'test': 2000}\n",
    "class_names = all_data.classes\n",
    "batch_size = 8\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "    'validation': torch.utils.data.DataLoader(valid_set, batch_size=batch_size),\n",
    "    'test': torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40e428",
   "metadata": {},
   "source": [
    "## Quantum Circuit Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b4fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model architecture/training params\n",
    "qubit_count = 4\n",
    "step = 0.0004  # Initial learning rate\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "circ_repeats = 6  # How many times to repeat RY and CNOT gates\n",
    "gamma_lr_scheduler = 0.1  # Learning rate decay param\n",
    "q_delta = 0.01  # Param for quantum circuit weight initialization\n",
    "\n",
    "# Run quantum circuit on Pennylane default simulator\n",
    "dev = qml.device('default.qubit', wires=qubit_count)\n",
    "\n",
    "# If GPU available, set to run on it\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to construct quantum circuit\n",
    "def ry_gates(w):\n",
    "    # Apply rotation gate RY w/ given weights\n",
    "    for i, weight in enumerate(w):\n",
    "        qml.RY(weight, wires=i)\n",
    "\n",
    "# Adds alternating CNOT layer to entangle qubits\n",
    "def entangling_layer(nqubits):\n",
    "    for i in range(0, nqubits - 1, 2):  # Evens\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Odds\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f695c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct quantum circuit to plug into PyTorch\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_circuit(inputs, q_weights_flat):\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(circ_repeats, qubit_count)\n",
    "    # Initialize w/ H gates so orthogonal to computational basis\n",
    "    # This helps start w/out bias towards 0 or 1 states\n",
    "    for i in range(qubit_count):\n",
    "        qml.Hadamard(wires=i)\n",
    "    # Take given inputs and apply to quantum circuit as first weights\n",
    "    ry_gates(inputs)\n",
    "    # Repeat CNOT and RY gates to add more weights to train and\n",
    "    # CNOT \"convolutions\" (really entangles)\n",
    "    for k in range(circ_repeats):\n",
    "        entangling_layer(qubit_count)\n",
    "        ry_gates(q_weights[k])\n",
    "    # Use Pennylane sim to get expected value after applying Z gate\n",
    "    # which returns to standard computational basis, this is layer output\n",
    "    expected_vals = [qml.expval(qml.PauliZ(entry)) for entry in range(qubit_count)]\n",
    "    return tuple(expected_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293270e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──H──RY(-1.36)─╭●──RY(-0.01)───────────╭●──RY(-0.00)────────────╭●──RY(-0.01)────────────╭●\n",
      "1: ──H──RY(0.59)──╰X─╭●──────────RY(0.00)─╰X─╭●──────────RY(0.00)──╰X─╭●──────────RY(-0.01)─╰X\n",
      "2: ──H──RY(-0.56)─╭●─╰X──────────RY(0.01)─╭●─╰X──────────RY(-0.01)─╭●─╰X──────────RY(-0.00)─╭●\n",
      "3: ──H──RY(-0.30)─╰X──RY(-0.01)───────────╰X──RY(-0.01)────────────╰X──RY(0.01)─────────────╰X\n",
      "\n",
      "───RY(-0.01)────────────╭●──RY(-0.01)────────────╭●──RY(0.01)───────────┤  <Z>\n",
      "──╭●──────────RY(0.00)──╰X─╭●──────────RY(-0.01)─╰X─╭●─────────RY(0.00)─┤  <Z>\n",
      "──╰X──────────RY(-0.01)─╭●─╰X──────────RY(-0.02)─╭●─╰X─────────RY(0.01)─┤  <Z>\n",
      "───RY(0.01)─────────────╰X──RY(-0.00)────────────╰X──RY(0.01)───────────┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "# Example visualization codes with nonsense weights\n",
    "# Helps to see what the quantum circuit looks like\n",
    "q_params_print = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "input_test = torch.randn(1,512)\n",
    "pre_net_test = nn.Linear(512, qubit_count)\n",
    "pre_out_test = pre_net_test(input_test)\n",
    "q_in_test = torch.tanh(pre_out_test) * np.pi / 2.0\n",
    "for elem in q_in_test:\n",
    "    print(qml.draw(quantum_circuit)(elem, q_params_print))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916720a3-5e54-4bee-b428-7be9e3252bdc",
   "metadata": {},
   "source": [
    "## HQNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c56560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HQNN Model Class\n",
    "class HybridQuantumNet(nn.Module):\n",
    "    # Initialize layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Layers before quantum circuit\n",
    "        self.pre_quant = nn.Linear(512, qubit_count)\n",
    "        # Quantum Circuit params\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(circ_repeats * qubit_count))\n",
    "        # Layer(s) after quantum circuit\n",
    "        self.post_quant = nn.Linear(qubit_count, 2)\n",
    "\n",
    "    # Forward pass procedure\n",
    "    def forward(self, input_features):\n",
    "        # Map 512 output to qubit_count output\n",
    "        pre_out = self.pre_quant(input_features)\n",
    "        # Convert to radians for use as RY rotation gate params\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "        # Apply quantum circuit to each batch image, set to run on GPU\n",
    "        q_out = torch.Tensor(0, qubit_count)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_circuit(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "        # Map quantum circuit output using linear layer to classes\n",
    "        return self.post_quant(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model_hybrid = HybridQuantumNet()\n",
    "# Make sure set to use GPU\n",
    "model_hybrid = model_hybrid.to(device)\n",
    "# Show model architecture summary\n",
    "model_hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ef09c-cd06-41b8-bd44-35bded59fab8",
   "metadata": {},
   "source": [
    "## Train HQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24238e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss, optimizer, and learning rate decay manager\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model(s)\n",
    "def train(model, loss_func, optimizer, scheduler, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 100000.0\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 100000.0\n",
    "    print('Training started:')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                # Set model to train mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to eval mode\n",
    "                model.eval()\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            iter = 0\n",
    "            for X, Y in dataloaders[phase]:\n",
    "                batch_len = len(X)\n",
    "                X = X.to(device)\n",
    "                X = X.to(device)\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "                # If in train mode, get loss, step optimizer\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(X)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = loss_func(outputs, Y)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # Print iteration results\n",
    "                current_loss += loss.item() * batch_len\n",
    "                batch_corrects = torch.sum(preds == X.data).item()\n",
    "                current_corrects += batch_corrects\n",
    "                print('Phase: {} Epoch: {}/{} Iter: {}/{}'.format(phase, epoch+1, num_epochs, iter+1, n_batches+1),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True)\n",
    "                iter += 1\n",
    "\n",
    "            # Get epoch stats and print\n",
    "            epoch_loss = current_loss / dataset_sizes[phase]\n",
    "            epoch_acc = current_corrects / dataset_sizes[phase]\n",
    "            print('Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        '.format(\n",
    "                    'train' if phase == 'train' else 'validation  ',\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "            # Update best var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = train(model_hybrid, loss_func, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights locally in case of GCP crash\n",
    "torch.save(model_hybrid.state_dict(), './weights/hybrid_10epochs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd073d9f-88a8-43c1-a147-1a6ca3baef3c",
   "metadata": {},
   "source": [
    "## Test HQNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef720e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved weights, put in model, and than set to eval mode\n",
    "best_weights = torch.load('./weights/hybrid_10epochs.pt')\n",
    "model_hybrid.load_state_dict(best_weights)\n",
    "model_hybrid.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04835ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests model (if epsilon=0, standard test set images)\n",
    "# Otherwise perturbs using FGSM attack\n",
    "# Also stores example images where the perturbation caused a mislabel\n",
    "def test(model, device, test_loader, epsilon):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # Send the data and label to GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # Don't care to attack if already wrong\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "        # Get loss backprop for gradient values\n",
    "        loss = F.nll_loss(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # Collect gradients\n",
    "        data_grad = data.grad.data\n",
    "        # Call FGSM function\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if epsilon == 0 and len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "    # Get accuracy metric\n",
    "    final_acc = correct / float(dataset_sizes['test'])\n",
    "    print('Epsilon: {}\\tTest Accuracy = {} / {} = {}'.format(epsilon, correct, len(test_loader), final_acc))\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e278d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
